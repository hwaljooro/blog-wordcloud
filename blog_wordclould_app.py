from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from bs4 import BeautifulSoup
from textblob import TextBlob
import nltk
import time
import matplotlib.pyplot as plt
from wordcloud import WordCloud
import sys
import os

# nltk ë°ì´í„° ë‹¤ìš´ë¡œë“œ (ìµœì´ˆ 1íšŒ)
nltk.download('punkt')

# í¬ë¡¬ ë“œë¼ì´ë²„ ì„¤ì •
chrome_options = Options()
chrome_options.add_argument("--headless")  # ì°½ ì—†ì´ ì‹¤í–‰
chrome_options.add_argument("--no-sandbox")
chrome_options.add_argument("--disable-dev-shm-usage")

# í™˜ê²½ì— ë”°ë¼ ë“œë¼ì´ë²„ ê²½ë¡œ ì„¤ì •
if os.getenv("GITHUB_ACTIONS") == "true":
    driver_path = "/usr/local/bin/chromedriver"  # GitHub Actionsìš©
else:
    from webdriver_manager.chrome import ChromeDriverManager
    driver_path = ChromeDriverManager().install()  # ë¡œì»¬ ìžë™ ì„¤ì¹˜

driver = webdriver.Chrome(executable_path=driver_path, options=chrome_options)


# ë¸”ë¡œê·¸ ë° ì¹´íŽ˜ ë°ì´í„° ìˆ˜ì§‘ í•¨ìˆ˜
def get_blog_data(query, start_date, end_date, max_pages):
    all_text = ""
    
    for page in range(1, max_pages + 1):
        url = f"https://search.naver.com/search.naver?where=view&query={query}&nso=so:dd,p:from{start_date}to{end_date}&start={(page - 1) * 10 + 1}"
        
        driver.get(url)
        time.sleep(2)
        
        soup = BeautifulSoup(driver.page_source, "html.parser")
        blog_items = soup.select(".api_txt_lines.total_tit")
        
        for item in blog_items:
            title = item.text.strip()
            all_text += " " + title
            
            blog_url = item['href']
            driver.get(blog_url)
            time.sleep(2)
            
            blog_soup = BeautifulSoup(driver.page_source, "html.parser")
            content = blog_soup.select_one(".se-main-container") or blog_soup.select_one("#contentArea") or blog_soup.select_one("article")

            if content:
                all_text += " " + content.get_text(separator=" ", strip=True)
    
    return all_text


# ê°ì„± ë¶„ì„ í•¨ìˆ˜
def analyze_sentiment(text):
    blob = TextBlob(text)
    polarity = blob.sentiment.polarity
    return "ê¸ì •" if polarity > 0 else "ë¶€ì •" if polarity < 0 else "ì¤‘ë¦½"


# ì›Œë“œí´ë¼ìš°ë“œ ìƒì„± í•¨ìˆ˜
def generate_wordcloud(text):
    wc = WordCloud(font_path="NanumGothic.ttf", width=800, height=400, background_color="white").generate(text)
    plt.figure(figsize=(12, 6))
    plt.imshow(wc, interpolation="bilinear")
    plt.axis("off")
    plt.tight_layout()
    plt.savefig("wordcloud.png")  # ì €ìž¥ (GitHubì—ì„œ í™•ì¸ ê°€ëŠ¥)
    plt.show()


# ì‹¤í–‰ ì˜ˆì‹œ
if __name__ == "__main__":
    query = "í”„ë£¨ë–¼"
    start_date = "20230401"
    end_date = "20250331"
    max_pages = 3

    print(f"ðŸ” '{query}'ì— ëŒ€í•œ ê²Œì‹œê¸€ì„ ê²€ìƒ‰ ì¤‘...")
    all_text = get_blog_data(query, start_date, end_date, max_pages)

    if all_text.strip() == "":
        print("â—ï¸ê²Œì‹œê¸€ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        sys.exit(1)

    # ê°ì„± ë¶„ì„ ê²°ê³¼
    sentiment_result = analyze_sentiment(all_text)
    print(f"\nðŸ’¬ ê°ì„± ë¶„ì„ ê²°ê³¼: {sentiment_result}")

    # ì›Œë“œí´ë¼ìš°ë“œ ìƒì„±
    print("ðŸŒ¥ ì›Œë“œí´ë¼ìš°ë“œ ìƒì„± ì¤‘...")
    generate_wordcloud(all_text)

    driver.quit()

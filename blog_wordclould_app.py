import streamlit as st
import requests
from bs4 import BeautifulSoup
import datetime
import time
import urllib.parse
from wordcloud import WordCloud
import matplotlib.pyplot as plt

# ê°ì„± ë‹¨ì–´ ì‚¬ì „
positive_words = [
    "ì¢‹ë‹¤", "ì¬ë°Œë‹¤", "ê°ë™", "ìµœê³ ", "ì¶”ì²œ", "ë§›ìˆë‹¤", "ìœ ìµí•˜ë‹¤", "í¥ë¯¸ë¡­ë‹¤", "ê´œì°®ë‹¤",
    "ì¦ê²ë‹¤", "í–‰ë³µí•˜ë‹¤", "ì¹œì ˆí•˜ë‹¤", "ì•„ë¦„ë‹µë‹¤", "ë©‹ì§€ë‹¤", "ê°ì‚¬í•˜ë‹¤", "ê°ê²©", "ëŒ€ë°•",
    "í™˜ìƒì ì´ë‹¤", "ì™„ë²½í•˜ë‹¤", "ê¸°ì˜ë‹¤", "ê¸°ë¶„ ì¢‹ë‹¤", "ë§Œì¡±ìŠ¤ëŸ½ë‹¤", "ê¸°ëŒ€ ì´ìƒ", "ì¸ìƒ ê¹Šë‹¤"
]

negative_words = [
    "ë³„ë¡œ", "ë‚˜ì˜ë‹¤", "ì§€ë£¨í•˜ë‹¤", "ìµœì•…", "ë¶ˆí¸", "ì‹¤ë§", "ì•„ì‰½ë‹¤", "ì§œì¦", "ë¹„ì¶”",
    "ë¶ˆë§Œ", "í˜•í¸ì—†ë‹¤", "ì‹¤ìˆ˜", "ë¶ˆì¾Œí•˜ë‹¤", "í›„íšŒ", "ì†ìƒí•˜ë‹¤", "ì§œì¦ë‚˜ë‹¤", "ì§€ì €ë¶„í•˜ë‹¤",
    "ë¶ˆì¹œì ˆ", "ì–´ì´ì—†ë‹¤", "ì˜ì™¸ë¡œ ë³„ë¡œ", "ì‹¤íŒ¨", "ë‹¤ì‹  ì•ˆ ê°„ë‹¤", "ì‹¤ë§ìŠ¤ëŸ½ë‹¤", "ë³„ë¡œì˜€ë‹¤"
]

def analyze_sentiment(text):
    pos = sum(text.count(w) for w in positive_words)
    neg = sum(text.count(w) for w in negative_words)
    if pos > neg:
        return "ê¸ì •"
    elif neg > pos:
        return "ë¶€ì •"
    else:
        return "ì¤‘ë¦½"

# Streamlit UI
st.title("ğŸ” ë„¤ì´ë²„ ë¸”ë¡œê·¸/ì¹´í˜ ê°ì„± ë¶„ì„ + ì›Œë“œí´ë¼ìš°ë“œ")
query = st.text_input("ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš”", "ì—¬ì£¼ ë†ì´Œì²´í—˜")

col1, col2 = st.columns(2)
with col1:
    start_date = st.date_input("ì‹œì‘ ë‚ ì§œ", datetime.date(2025, 3, 1))
with col2:
    end_date = st.date_input("ì¢…ë£Œ ë‚ ì§œ", datetime.date(2025, 4, 20))

max_pages = st.slider("ê²€ìƒ‰í•  í˜ì´ì§€ ìˆ˜", 1, 10, 3)

if st.button("ë¶„ì„ ì‹œì‘"):
    with st.spinner("ë„¤ì´ë²„ ë°ì´í„° ìˆ˜ì§‘ ì¤‘..."):
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 "
                          "(KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
        }

        sentiment_results = {"ê¸ì •": 0, "ë¶€ì •": 0, "ì¤‘ë¦½": 0}
        detailed_results = []
        all_text = ""

        for page in range(1, max_pages + 1):
            start = (page - 1) * 10 + 1
            encoded_query = urllib.parse.quote(query)
            url = (
                f"https://search.naver.com/search.naver"
                f"?where=view&query={encoded_query}"
                f"&nso=so%3Add%2Cp%3Afrom{start_date.strftime('%Y%m%d')}to{end_date.strftime('%Y%m%d')}"
                f"&start={start}"
            )

            st.info(f"[{page}í˜ì´ì§€ ìš”ì²­ ì¤‘] URL: {url}")

            try:
                res = requests.get(url, headers=headers, timeout=5)
                soup = BeautifulSoup(res.text, "html.parser")
                total_items = soup.select(".total_wrap.api_ani_send")  # í•µì‹¬ ì…€ë ‰í„°

                if not total_items:
                    st.warning(f"{page}í˜ì´ì§€ì— ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
                    continue

                for item in total_items:
                    title_tag = item.select_one(".api_txt_lines.total_tit")
                    desc_tag = item.select_one(".total_dsc")

                    title = title_tag.get_text(strip=True) if title_tag else ""
                    description = desc_tag.get_text(strip=True) if desc_tag else ""
                    text = f"{title} {description}"
                    all_text += " " + text

                    sentiment = analyze_sentiment(text)
                    sentiment_results[sentiment] += 1
                    detailed_results.append((title, sentiment))

                time.sleep(1)

            except Exception as e:
                st.error(f"âŒ {page}í˜ì´ì§€ ì˜¤ë¥˜: {e}")
                break

        if not all_text.strip():
            st.error("âŒ ë¶„ì„í•  í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤. ê²€ìƒ‰ì–´ ë˜ëŠ” ê¸°ê°„ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
        else:
            st.subheader("ğŸ“Š ê°ì„± ë¶„ì„ ê²°ê³¼")
            st.success(f"ğŸ‘ ê¸ì •: {sentiment_results['ê¸ì •']}ê°œ")
            st.warning(f"ğŸ˜ ì¤‘ë¦½: {sentiment_results['ì¤‘ë¦½']}ê°œ")
            st.error(f"ğŸ‘ ë¶€ì •: {sentiment_results['ë¶€ì •']}ê°œ")

            with st.expander("ê²Œì‹œê¸€ë³„ ê°ì„± ë¶„ì„ ê²°ê³¼"):
                for i, (title, sentiment) in enumerate(detailed_results, 1):
                    st.write(f"{i}. [{sentiment}] {title}")

            st.subheader("â˜ï¸ ì›Œë“œí´ë¼ìš°ë“œ")
            wc = WordCloud(font_path="NanumGothic.ttf", width=800, height=400, background_color="white").generate(all_text)
            fig, ax = plt.subplots(figsize=(12, 6))
            ax.imshow(wc, interpolation='bilinear')
            ax.axis("off")
            st.pyplot(fig)

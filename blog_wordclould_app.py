import streamlit as st
import requests
from bs4 import BeautifulSoup
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from webdriver_manager.chrome import ChromeDriverManager
import time
import datetime
import urllib.parse
from wordcloud import WordCloud
import matplotlib.pyplot as plt

# ê°ì„± ë‹¨ì–´ ì‚¬ì „
positive_words = ["ì¢‹ë‹¤", "ìµœê³ ", "ì¶”ì²œ", "ë§›ìˆë‹¤", "ì¬ë°Œë‹¤", "ì¦ê²ë‹¤", "ê°ë™", "ê°ì‚¬", "ë©‹ì§€ë‹¤"]
negative_words = ["ë³„ë¡œ", "ìµœì•…", "ì‹¤ë§", "ë¶ˆí¸", "ì•„ì‰½ë‹¤", "ì§œì¦", "ë‚˜ì˜ë‹¤", "í›„íšŒ", "ì§€ë£¨í•˜ë‹¤"]

def analyze_sentiment(text):
    pos = sum([text.count(w) for w in positive_words])
    neg = sum([text.count(w) for w in negative_words])
    if pos > neg:
        return "ê¸ì •"
    elif neg > pos:
        return "ë¶€ì •"
    else:
        return "ì¤‘ë¦½"

def get_text_from_url_selenium(driver, url):
    try:
        driver.get("https://www.naver.com")
        time.sleep(2)
        soup = BeautifulSoup(driver.page_source, "html.parser")
        content = soup.select_one(".se-main-container")  # ë¸”ë¡œê·¸ ê¸€
        if not content:
            content = soup.select_one("#contentArea")  # ì¹´í˜ ê¸€
        return content.get_text(separator=" ") if content else ""
    except Exception as e:
        return ""

# UI
st.title("ğŸ§  ë³¸ë¬¸ ê¸°ë°˜ ê°ì„± ë¶„ì„ê¸° (ë„¤ì´ë²„ ë¸”ë¡œê·¸/ì¹´í˜)")
query = st.text_input("ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš”", "ì—¬ì£¼ ë†ì´Œì²´í—˜")

col1, col2 = st.columns(2)
with col1:
    start_date = st.date_input("ì‹œì‘ ë‚ ì§œ", datetime.date(2025, 3, 1))
with col2:
    end_date = st.date_input("ì¢…ë£Œ ë‚ ì§œ", datetime.date(2025, 4, 20))

max_pages = st.slider("ê²€ìƒ‰í•  í˜ì´ì§€ ìˆ˜", 1, 5, 2)

if st.button("ë¶„ì„ ì‹œì‘"):
    with st.spinner("í¬ë¡¬ ë¸Œë¼ìš°ì €ë¥¼ ì‹¤í–‰í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
        chrome_options = Options()
        chrome_options.add_argument("--headless")
        chrome_options.add_argument("--no-sandbox")
        chrome_options.add_argument("--disable-dev-shm-usage")
        driver = webdriver.Chrome(ChromeDriverManager().install())

    sentiment_results = {"ê¸ì •": 0, "ë¶€ì •": 0, "ì¤‘ë¦½": 0}
    detailed_results = []
    all_text = ""

    with st.spinner("ë°ì´í„° ìˆ˜ì§‘ ì¤‘..."):
        headers = {"User-Agent": "Mozilla/5.0"}
        for page in range(1, max_pages + 1):
            start = (page - 1) * 10 + 1
            encoded_query = urllib.parse.quote(query)
            url = (
                f"https://search.naver.com/search.naver"
                f"?where=view&query={encoded_query}"
                f"&nso=so%3Add%2Cp%3Afrom{start_date.strftime('%Y%m%d')}to{end_date.strftime('%Y%m%d')}"
                f"&start={start}"
            )

            res = requests.get(url, headers=headers)
            soup = BeautifulSoup(res.text, "html.parser")
            items = soup.select(".total_wrap.api_ani_send")

            for item in items:
                link_tag = item.select_one(".api_txt_lines.total_tit")
                if not link_tag:
                    continue
                title = link_tag.get_text(strip=True)
                href = link_tag["href"]

                body = get_text_from_url_selenium(driver, href)
                full_text = title + " " + body
                sentiment = analyze_sentiment(full_text)
                sentiment_results[sentiment] += 1
                detailed_results.append((title, sentiment))
                all_text += " " + full_text

            time.sleep(1)

        driver.quit()

    if not all_text.strip():
        st.error("âŒ ë³¸ë¬¸ ìˆ˜ì§‘ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ê²€ìƒ‰ì–´ ë˜ëŠ” ê¸°ê°„ì„ ë‹¤ì‹œ í™•ì¸í•´ì£¼ì„¸ìš”.")
    else:
        st.subheader("ğŸ“Š ê°ì„± ë¶„ì„ ê²°ê³¼")
        st.success(f"ğŸ‘ ê¸ì •: {sentiment_results['ê¸ì •']}ê°œ")
        st.warning(f"ğŸ˜ ì¤‘ë¦½: {sentiment_results['ì¤‘ë¦½']}ê°œ")
        st.error(f"ğŸ‘ ë¶€ì •: {sentiment_results['ë¶€ì •']}ê°œ")

        with st.expander("ğŸ” ê²Œì‹œê¸€ë³„ ê°ì„± ë¶„ì„"):
            for i, (title, sentiment) in enumerate(detailed_results, 1):
                st.write(f"{i}. [{sentiment}] {title}")

        st.subheader("â˜ï¸ ì›Œë“œí´ë¼ìš°ë“œ")
        wc = WordCloud(font_path="NanumGothic.ttf", width=800, height=400, background_color="white").generate(all_text)
        fig, ax = plt.subplots(figsize=(12, 6))
        ax.imshow(wc, interpolation="bilinear")
        ax.axis("off")
        st.pyplot(fig)
